мои лекции:

Эвристический поиск. Экспертные системы.	2/21/15	Сошников
Неклассические и нечеткие логики	2/28/15	Баскаков
Case-based Reasoning	3/14/15	Баскаков
Байесовские сети	3/21/15	Баскаков


TODO: смержить разные курсы в общую программу

# UC Berkeley's upper division course CS188

Syllabus

Introduction
	Overview
	Agents: Perception, Decisions, and Actuation

Search and Planning
	Uninformed Search (Depth-First, Breadth-First, Uniform-Cost)
	Informed Search (A*, Greedy Search)
	Heuristics and Optimality

Constraint Satisfaction Problems
	Backtracking Search
	Constraint Propagation (Arc Consistency)
	Exploiting Graph Structure

Game Trees and Tree-Structured Computation
	Minimax, Expectimax, Combinations
	Evaluation Functions and Approximations
	Alpha-Beta Pruning

Decision Theory
	Preferences, Rationality, and Utilities
	Maximum Expected Utility

Markov Decision Processes
	Policies, Rewards, and Values
	Value Iteration
	Policy Iteration

Reinforcement Learning
	TD/Q Learning
	Exploration
	Approximation

==================================================================


Syllabus
The following is a tentative syllabus for the class:

Introduction to Machine Learning. Univariate linear regression. (Optional: Linear algebra review.)
Multivariate linear regression. Practical aspects of implementation. Octave tutorial.
Logistic regression, One-vs-all classification, Regularization.
Neural Networks.
Practical advice for applying learning algorithms: How to develop, debugging, feature/model design, setting up experiment structure.
Support Vector Machines (SVMs) and the intuition behind them.
Unsupervised learning: clustering and dimensionality reduction.
Anomaly detection.
Recommender systems.
Large-scale machine learning. An example of an application of machine learning.



====================================================================================

# задания из курса ML в Stanford


IV. Linear Regression with Multiple Variables (Week 2)
(expanded, click to collapse)
Linear Regression


VII. Regularization (Week 3)
(expanded, click to collapse)
Logistic Regression


VIII. Neural Networks: Representation (Week 4)
(expanded, click to collapse)
Multi-class Classification and Neural Networks


IX. Neural Networks: Learning (Week 5)
(expanded, click to collapse)
Neural Network Learning


X. Advice for Applying Machine Learning (Week 6)
(expanded, click to collapse)
Regularized Linear Regression and Bias/Variance


XII. Support Vector Machines (Week 7)
(expanded, click to collapse)
Support Vector Machines Help


XIV. Dimensionality Reduction (Week 8)
(expanded, click to collapse)
K-Means Clustering and PCA



XVI. Recommender Systems (Week 9)
(expanded, click to collapse)
Anomaly Detection and Recommender Systems


===========================================================

Gradient Boosted Decision Tree algorithm

A popular open-source implementation[9] for R calls it "Generalized Boosting Model". Sometimes the method is referred to as "functional gradient boosting" (this term was introduced in,[3][4]), "Gradient Boosted Models" and its tree version is also called "Gradient Boosted Decision Trees" (GBDT) or "Gradient Boosted Regression Trees" (GBRT). Commercial implementations from Salford Systems use the names "Multiple Additive Regression Trees" (MART) and TreeNet, both trademarked. Commercial implementations from FICO call the Boosted Tree Ensemble (BTE) method. The FICO implementation is available in FICO® Model Builder on the desktop and FICO® Analytic Modeler Scorecard in the FICO® Analytic Cloud


===========================================================

Use regularization instead of PCA!!


The R2014b Mac OS X (Intel 64-bit) installer is downloading now.
Next Step: Run the installer and log in as spetz911@gmail.com and select license id 1065519.































